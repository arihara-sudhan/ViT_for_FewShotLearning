{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Test on Data with Intraclass Variance : ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-11-09T09:02:24.257019Z",
     "iopub.status.busy": "2023-11-09T09:02:24.256133Z",
     "iopub.status.idle": "2023-11-09T09:02:24.264414Z",
     "shell.execute_reply": "2023-11-09T09:02:24.263370Z",
     "shell.execute_reply.started": "2023-11-09T09:02:24.256983Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, ViTModel\n",
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.optim import Adam,lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.nn.parallel import DataParallel\n",
    "import torchvision.models as models\n",
    "from PIL import Image, ImageFile\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import faiss\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "np.object = np.object_\n",
    "np.int = np.int_\n",
    "np.bool = np.bool_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRIPLET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T09:02:26.871980Z",
     "iopub.status.busy": "2023-11-09T09:02:26.871313Z",
     "iopub.status.idle": "2023-11-09T09:02:26.886098Z",
     "shell.execute_reply": "2023-11-09T09:02:26.885006Z",
     "shell.execute_reply.started": "2023-11-09T09:02:26.871946Z"
    }
   },
   "outputs": [],
   "source": [
    "class Triplet:\n",
    "    def __init__(self, train_folder):\n",
    "        self.train_folder = train_folder\n",
    "        self.labels = [label for label in os.listdir(train_folder) if label != '.ipynb_checkpoints']\n",
    "        self.label_to_path = {label: os.path.join(train_folder, label) for label in self.labels}\n",
    "\n",
    "    def get_triplet(self):\n",
    "        anchor_label = random.choice(self.labels)\n",
    "        anchor_path = random.choice(os.listdir(self.label_to_path[anchor_label]))\n",
    "        positive_label = anchor_label\n",
    "        positive_path = random.choice(os.listdir(self.label_to_path[positive_label]))\n",
    "        negative_label = random.choice([label for label in self.labels if label != anchor_label])\n",
    "        negative_path = random.choice(os.listdir(self.label_to_path[negative_label]))\n",
    "\n",
    "        anchor_image = os.path.join(self.label_to_path[anchor_label], anchor_path)\n",
    "        positive_image = os.path.join(self.label_to_path[positive_label], positive_path)\n",
    "        negative_image = os.path.join(self.label_to_path[negative_label], negative_path)\n",
    "\n",
    "        anchor_label_num = self.labels.index(anchor_label)\n",
    "        positive_label_num = self.labels.index(positive_label)\n",
    "        negative_label_num = self.labels.index(negative_label)\n",
    "\n",
    "        return anchor_image, positive_image, negative_image\n",
    "\n",
    "class TripletDataset(Dataset):\n",
    "    def __init__(self, train_folder, length, transform=None,):\n",
    "        self.triplet_generator = Triplet(train_folder)\n",
    "        self.transform = transform\n",
    "        self.length = length\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        anchor_image, positive_image, negative_image = self.triplet_generator.get_triplet()\n",
    "        anchor = self._load_image(anchor_image)\n",
    "        positive = self._load_image(positive_image)\n",
    "        negative = self._load_image(negative_image)\n",
    "        return anchor, positive, negative\n",
    "\n",
    "    def _load_image(self, image_path):\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "    def get_triplet_names(self, index):\n",
    "        anchor_image, positive_image, negative_image = self.triplet_generator.get_triplet()\n",
    "        return anchor_image, positive_image, negative_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T09:02:29.221437Z",
     "iopub.status.busy": "2023-11-09T09:02:29.220757Z",
     "iopub.status.idle": "2023-11-09T09:02:29.773497Z",
     "shell.execute_reply": "2023-11-09T09:02:29.772466Z",
     "shell.execute_reply.started": "2023-11-09T09:02:29.221402Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subfolder: lynx_canadensis, Number of Files: 130\n",
      "Subfolder: loxodonta_cyclotis, Number of Files: 130\n",
      "Subfolder: leptailurus_serval, Number of Files: 130\n",
      "Subfolder: acinonyx_jubatus, Number of Files: 130\n",
      "Subfolder: leopardus_wiedii, Number of Files: 130\n",
      "Subfolder: felis_silvestris, Number of Files: 130\n",
      "Subfolder: leopardus_pardalis, Number of Files: 130\n",
      "Subfolder: elephas_maximus, Number of Files: 130\n",
      "Subfolder: herpailurus_yagouaroundi, Number of Files: 130\n",
      "Subfolder: felis_lybica, Number of Files: 130\n",
      "1300\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "folder_path = \"/kaggle/input/animals-insects-reptiles/Animals-Insects-Reptiles/Species-Train\"\n",
    "\n",
    "# Get a list of subfolders in the specified folder\n",
    "subfolders = [subfolder for subfolder in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, subfolder))]\n",
    "\n",
    "total = 0\n",
    "# Iterate through the subfolders and count the number of files in each\n",
    "for subfolder in subfolders:\n",
    "    subfolder_path = os.path.join(folder_path, subfolder)\n",
    "    num_files = len([filename for filename in os.listdir(subfolder_path) if os.path.isfile(os.path.join(subfolder_path, filename))])\n",
    "    print(f\"Subfolder: {subfolder}, Number of Files: {num_files}\")\n",
    "    total += num_files\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T09:02:32.070182Z",
     "iopub.status.busy": "2023-11-09T09:02:32.069796Z",
     "iopub.status.idle": "2023-11-09T09:02:32.077535Z",
     "shell.execute_reply": "2023-11-09T09:02:32.076545Z",
     "shell.execute_reply.started": "2023-11-09T09:02:32.070151Z"
    }
   },
   "outputs": [],
   "source": [
    "bs = 16\n",
    "train_folder = \"/kaggle/input/animals-insects-reptiles/Animals-Insects-Reptiles/Species-Train\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to 224x224\n",
    "    transforms.ToTensor(),           # Convert to a PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize the tensor\n",
    "])\n",
    "train_dataset = TripletDataset(train_folder, 1300, transform=transform, )\n",
    "train_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T09:03:07.837563Z",
     "iopub.status.busy": "2023-11-09T09:03:07.837186Z",
     "iopub.status.idle": "2023-11-09T09:03:09.021596Z",
     "shell.execute_reply": "2023-11-09T09:03:09.020752Z",
     "shell.execute_reply.started": "2023-11-09T09:03:07.837534Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class TEmbeddingNet(nn.Module):\n",
    "    def __init__(self, modelt):\n",
    "        super(TEmbeddingNet, self).__init__()\n",
    "        self.modelt = modelt\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.modelt(x)  # Shape: (batch_size, 2048, H, W)\n",
    "        return x.last_hidden_state\n",
    "\n",
    "    def get_embedding(self, x):\n",
    "        x = self.modelt(x)  # Shape: (batch_size, 2048, H, W)\n",
    "        return x.last_hidden_state\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "model = ViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "\n",
    "tmodel = TEmbeddingNet(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T09:03:13.224001Z",
     "iopub.status.busy": "2023-11-09T09:03:13.223499Z",
     "iopub.status.idle": "2023-11-09T09:03:13.231405Z",
     "shell.execute_reply": "2023-11-09T09:03:13.230359Z",
     "shell.execute_reply.started": "2023-11-09T09:03:13.223948Z"
    }
   },
   "outputs": [],
   "source": [
    "class TripletNet(nn.Module):\n",
    "    def __init__(self, embedding_net):\n",
    "        super(TripletNet, self).__init__()\n",
    "        self.enet = embedding_net\n",
    "\n",
    "    def forward(self, x1, x2=None, x3=None):\n",
    "        if x2 is None and x3 is None:\n",
    "            return self.enet.get_embedding(x1)\n",
    "        return self.enet.get_embedding(x1),self.enet.get_embedding(x2),self.enet.get_embedding(x3)\n",
    "\n",
    "    def get_embedding(self, x):\n",
    "        return self.enet.get_embedding(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss, Device, Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T09:03:14.730427Z",
     "iopub.status.busy": "2023-11-09T09:03:14.729804Z",
     "iopub.status.idle": "2023-11-09T09:03:14.737047Z",
     "shell.execute_reply": "2023-11-09T09:03:14.736052Z",
     "shell.execute_reply.started": "2023-11-09T09:03:14.730394Z"
    }
   },
   "outputs": [],
   "source": [
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, anchor, positive, negative, size_average=True):\n",
    "        distance_positive = torch.norm(anchor - positive, dim=1)\n",
    "        distance_negative = torch.norm(anchor - negative, dim=1)\n",
    "        losses = F.relu(distance_positive - distance_negative + self.margin)\n",
    "        return losses.mean() if size_average else losses.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T09:03:16.095380Z",
     "iopub.status.busy": "2023-11-09T09:03:16.094719Z",
     "iopub.status.idle": "2023-11-09T09:03:16.189574Z",
     "shell.execute_reply": "2023-11-09T09:03:16.188772Z",
     "shell.execute_reply.started": "2023-11-09T09:03:16.095337Z"
    }
   },
   "outputs": [],
   "source": [
    "model = TripletNet(tmodel)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = nn.DataParallel(TripletNet(tmodel))\n",
    "else:\n",
    "    model = TripletNet(tmodel)\n",
    "# Move the model to the selected device (CPU or GPU)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T09:03:17.983858Z",
     "iopub.status.busy": "2023-11-09T09:03:17.982975Z",
     "iopub.status.idle": "2023-11-09T09:03:17.992114Z",
     "shell.execute_reply": "2023-11-09T09:03:17.991121Z",
     "shell.execute_reply.started": "2023-11-09T09:03:17.983825Z"
    }
   },
   "outputs": [],
   "source": [
    "margin = 1\n",
    "lr = 0.0001\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = StepLR(optimizer, step_size=3, gamma=0.5)  # Learning rate scheduler\n",
    "loss_fn = TripletLoss(margin)\n",
    "clip_value = 0.5  # You can adjust this value as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T09:03:20.800608Z",
     "iopub.status.busy": "2023-11-09T09:03:20.800236Z",
     "iopub.status.idle": "2023-11-09T09:16:52.554556Z",
     "shell.execute_reply": "2023-11-09T09:16:52.553491Z",
     "shell.execute_reply.started": "2023-11-09T09:03:20.800575Z"
    }
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "NO OF EPOCHS :  10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9419780969619751\n",
      "0.5718819499015808\n",
      "0.46392497420310974\n",
      "0.435746431350708\n",
      "0.3477965295314789\n",
      "0.2732747197151184\n",
      "0.41396546363830566\n",
      "0.6759012937545776\n",
      "0.2052626609802246\n",
      "Epoch 1/10, Train Loss: 0.4697, TIME: 80.2966718673706\n",
      "0.26862633228302\n",
      "0.18844661116600037\n",
      "0.36903461813926697\n",
      "0.2968551516532898\n",
      "0.35544896125793457\n",
      "0.27230557799339294\n",
      "0.44292712211608887\n",
      "0.37228116393089294\n",
      "0.19519975781440735\n",
      "Epoch 2/10, Train Loss: 0.2761, TIME: 80.65482115745544\n",
      "0.2640100419521332\n",
      "0.24788737297058105\n",
      "0.39497971534729004\n",
      "0.32253706455230713\n",
      "0.17366936802864075\n",
      "0.2623654007911682\n",
      "0.1968090832233429\n",
      "0.22086220979690552\n",
      "0.16596153378486633\n",
      "Epoch 3/10, Train Loss: 0.2431, TIME: 80.38875031471252\n",
      "0.07644326984882355\n",
      "0.14680920541286469\n",
      "0.17981955409049988\n",
      "0.07786305993795395\n",
      "0.0982128381729126\n",
      "0.011171698570251465\n",
      "0.0975198969244957\n",
      "0.09838885068893433\n",
      "0.042773425579071045\n",
      "Epoch 4/10, Train Loss: 0.1247, TIME: 80.11810731887817\n",
      "0.1397906392812729\n",
      "0.17582854628562927\n",
      "0.24987852573394775\n",
      "0.046027831733226776\n",
      "0.14843887090682983\n",
      "0.19662456214427948\n",
      "0.3677595257759094\n",
      "0.22430455684661865\n",
      "0.00719662569463253\n",
      "Epoch 5/10, Train Loss: 0.1465, TIME: 80.31243848800659\n",
      "0.20315182209014893\n",
      "0.10146515816450119\n",
      "0.14878305792808533\n",
      "0.10004018992185593\n",
      "0.10233986377716064\n",
      "0.021981220692396164\n",
      "0.13428665697574615\n",
      "0.17128199338912964\n",
      "0.0025357366539537907\n",
      "Epoch 6/10, Train Loss: 0.1097, TIME: 80.00599908828735\n",
      "0.0663423091173172\n",
      "0.1391291320323944\n",
      "0.007641249801963568\n",
      "0.017299721017479897\n",
      "0.07064850628376007\n",
      "0.10129714012145996\n",
      "0.04029923304915428\n",
      "0.07804512977600098\n",
      "0.12133878469467163\n",
      "Epoch 7/10, Train Loss: 0.1054, TIME: 79.95464825630188\n",
      "0.15224799513816833\n",
      "0.1665876805782318\n",
      "0.06742990761995316\n",
      "0.2403087317943573\n",
      "0.1212754100561142\n",
      "0.07589870691299438\n",
      "0.008376684039831161\n",
      "0.163784921169281\n",
      "0.18933449685573578\n",
      "Epoch 8/10, Train Loss: 0.0804, TIME: 80.25803828239441\n",
      "0.09380786120891571\n",
      "0.13681195676326752\n",
      "0.1399201601743698\n",
      "0.1564205288887024\n",
      "0.06476814299821854\n",
      "0.002305734669789672\n",
      "0.13023251295089722\n",
      "0.06630711257457733\n",
      "0.11861369013786316\n",
      "Epoch 9/10, Train Loss: 0.0716, TIME: 80.37299084663391\n",
      "0.009764703921973705\n",
      "0.007891553454101086\n",
      "0.08493980020284653\n",
      "0.12484626471996307\n",
      "0.0889645665884018\n",
      "0.1673537939786911\n",
      "0.019437862560153008\n",
      "0.08364289253950119\n",
      "0.10563749074935913\n",
      "Epoch 10/10, Train Loss: 0.0771, TIME: 80.44750666618347\n"
     ]
    }
   ],
   "source": [
    "def fit(model, num_epochs, train_loader, bs):\n",
    "    for epoch in range(n_epochs):\n",
    "        start = time.time()\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for idx, batch in enumerate(train_loader):\n",
    "            anchor, positive, negative = batch\n",
    "            anchor = anchor.to(device)\n",
    "            positive = positive.to(device)\n",
    "            negative = negative.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            anchor_embedding, positive_embedding, negative_embedding = model(anchor, positive, negative)\n",
    "            anchor_embedding.requires_grad_(True)\n",
    "            positive_embedding.requires_grad_(True)\n",
    "            negative_embedding.requires_grad_(True)\n",
    "            loss = loss_fn(anchor_embedding, positive_embedding, negative_embedding)\n",
    "            loss.backward()\n",
    "            clip_grad_norm_(model.parameters(), clip_value)\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            if idx%10==0:\n",
    "                print(loss.item())\n",
    "        print(f\"Epoch {epoch + 1}/{n_epochs}, Train Loss: {train_loss / len(train_loader):.4f}, TIME: {time.time()-start}\")\n",
    "        scheduler.step()\n",
    "\n",
    "\n",
    "fit(model, n_epochs:=int(input(\"NO OF EPOCHS : \")), train_loader, bs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T09:16:57.496638Z",
     "iopub.status.busy": "2023-11-09T09:16:57.496282Z",
     "iopub.status.idle": "2023-11-09T09:16:57.506288Z",
     "shell.execute_reply": "2023-11-09T09:16:57.505314Z",
     "shell.execute_reply.started": "2023-11-09T09:16:57.496608Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, folder_path, transform=None):\n",
    "        self.folder_path = folder_path\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        self._load_images()\n",
    "\n",
    "    def _load_images(self):\n",
    "        valid_extensions = ('.jpg', '.jpeg', '.png', '.ppm', '.bmp', '.pgm', '.tif', '.tiff', '.webp')\n",
    "        for class_name in os.listdir(self.folder_path):\n",
    "            class_folder = os.path.join(self.folder_path, class_name)\n",
    "            if os.path.isdir(class_folder):\n",
    "                for filename in os.listdir(class_folder):\n",
    "                    if filename.lower().endswith(valid_extensions):\n",
    "                        self.image_paths.append(os.path.join(class_folder, filename))\n",
    "                        self.labels.append(class_name)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T09:17:02.995279Z",
     "iopub.status.busy": "2023-11-09T09:17:02.994590Z",
     "iopub.status.idle": "2023-11-09T09:17:03.031593Z",
     "shell.execute_reply": "2023-11-09T09:17:03.030897Z",
     "shell.execute_reply.started": "2023-11-09T09:17:02.995249Z"
    }
   },
   "outputs": [],
   "source": [
    "train_folder = \"/kaggle/input/animals-insects-reptiles/Animals-Insects-Reptiles/Species-Train\"\n",
    "train_dataloader = DataLoader(CustomDataset(train_folder,transform=transform))\n",
    "test_folder = \"/kaggle/input/animals-insects-reptiles/Animals-Insects-Reptiles/Species-Test\"\n",
    "test_dataloader = DataLoader(CustomDataset(test_folder,transform=transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T05:37:46.431660Z",
     "iopub.status.busy": "2023-11-09T05:37:46.431373Z",
     "iopub.status.idle": "2023-11-09T05:37:46.436174Z",
     "shell.execute_reply": "2023-11-09T05:37:46.435176Z",
     "shell.execute_reply.started": "2023-11-09T05:37:46.431634Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T09:17:05.115274Z",
     "iopub.status.busy": "2023-11-09T09:17:05.114456Z",
     "iopub.status.idle": "2023-11-09T09:17:29.125388Z",
     "shell.execute_reply": "2023-11-09T09:17:29.124455Z",
     "shell.execute_reply.started": "2023-11-09T09:17:05.115244Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1300/1300 [00:24<00:00, 54.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.004308462142944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "train_embs = None\n",
    "train_labels = []\n",
    "for i in tqdm(train_dataloader):\n",
    "    I, L = i\n",
    "    train_labels.append(L)\n",
    "    emb = tmodel(I.to(device)) # Assuming `model_loaded(I)` returns a PyTorch tensor\n",
    "    emb = emb.detach()\n",
    "    if train_embs is None:\n",
    "        train_embs = emb\n",
    "    else:\n",
    "        train_embs = torch.cat((train_embs, emb), dim=0)\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T09:17:32.408357Z",
     "iopub.status.busy": "2023-11-09T09:17:32.407867Z",
     "iopub.status.idle": "2023-11-09T09:17:35.435219Z",
     "shell.execute_reply": "2023-11-09T09:17:35.434137Z",
     "shell.execute_reply.started": "2023-11-09T09:17:32.408313Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:03<00:00, 66.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.020395517349243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "test_embs = None\n",
    "test_labels = []\n",
    "for i in tqdm(test_dataloader):\n",
    "    I, L = i\n",
    "    try:\n",
    "        emb = tmodel(I.to(device)) # Assuming `model_loaded(I)` returns a PyTorch tensor\n",
    "        emb = emb.detach()\n",
    "        if test_embs is None:\n",
    "            test_embs = emb\n",
    "        else:\n",
    "            test_embs = torch.cat((test_embs, emb), dim=0)\n",
    "        test_labels.append(L)\n",
    "    except:\n",
    "        print(\"ERROR\")\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T09:17:38.282084Z",
     "iopub.status.busy": "2023-11-09T09:17:38.281396Z",
     "iopub.status.idle": "2023-11-09T09:18:22.426481Z",
     "shell.execute_reply": "2023-11-09T09:18:22.425438Z",
     "shell.execute_reply.started": "2023-11-09T09:17:38.282050Z"
    }
   },
   "outputs": [],
   "source": [
    "embs_cpu_np = train_embs.cpu().numpy()\n",
    "embs_cpu_np = embs_cpu_np.reshape(embs_cpu_np.shape[0], -1)\n",
    "index = faiss.IndexHNSWFlat(embs_cpu_np.shape[1], 32)  # M = 32 for the HNSW index\n",
    "index.add(embs_cpu_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T09:18:34.786562Z",
     "iopub.status.busy": "2023-11-09T09:18:34.785714Z",
     "iopub.status.idle": "2023-11-09T09:18:34.793438Z",
     "shell.execute_reply": "2023-11-09T09:18:34.792369Z",
     "shell.execute_reply.started": "2023-11-09T09:18:34.786530Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_with_faiss(embs, index):\n",
    "    TOTAL = len(embs)\n",
    "    CORRECT = 0\n",
    "    start = time.time()\n",
    "    \n",
    "    # Initialize the tqdm progress bar\n",
    "    with tqdm(total=TOTAL) as pbar:\n",
    "        for idx, emb in enumerate(embs):\n",
    "            label = index.search(emb.reshape(1, -1), 1)[1][0][0]\n",
    "            if train_labels[label][0] == test_labels[idx][0]:\n",
    "                CORRECT += 1\n",
    "            pbar.update(1)  # Update the progress bar\n",
    "\n",
    "    accuracy = (CORRECT / TOTAL) * 100\n",
    "    elapsed_time = time.time() - start\n",
    "    return f'Accuracy: {CORRECT}/{TOTAL} = {accuracy:.2f}%, Time: {elapsed_time:.2f} seconds'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T09:18:40.226075Z",
     "iopub.status.busy": "2023-11-09T09:18:40.225341Z",
     "iopub.status.idle": "2023-11-09T09:18:40.333108Z",
     "shell.execute_reply": "2023-11-09T09:18:40.331923Z",
     "shell.execute_reply.started": "2023-11-09T09:18:40.226038Z"
    }
   },
   "outputs": [],
   "source": [
    "embs2_cpu_np = test_embs.cpu().numpy()\n",
    "embs2_cpu_np = embs2_cpu_np.reshape(embs2_cpu_np.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T09:18:41.887585Z",
     "iopub.status.busy": "2023-11-09T09:18:41.887222Z",
     "iopub.status.idle": "2023-11-09T09:18:50.209564Z",
     "shell.execute_reply": "2023-11-09T09:18:50.208643Z",
     "shell.execute_reply.started": "2023-11-09T09:18:41.887556Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:08<00:00, 24.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IndexHNSWFlat : Accuracy: 155/200 = 77.50%, Time: 8.32 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'IndexHNSWFlat : {evaluate_with_faiss(embs2_cpu_np,index)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
